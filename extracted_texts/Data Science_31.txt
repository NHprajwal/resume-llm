JESSICA CLAIRE

100 Montgomery St. 10th Floor
(555) 432-1000 - resumesample@example.com

Wessrrte, Portrorio, PROFILES

¢ https://github.com/Claire007
« http://plotme.org/
¢ http://snowflect.com/

EpucatTIon

11/2011

08/2007

CERTIFICATIONS

Ph.D.: Materials Science & Engineering
McGill University - Montreal, QC

Master of Science: Materials Science & Engineering
McGill University - Montreal QC

Project Management Professional (PMP), PMI
Six Sigma Black Belt (CSSBB), ASQ
Professional Engineer (PEng.), PEO

SKILLS

¢ ML models (Regression, Classification, Clustering) ¢ NLP (vectorizer, word embedding - transfer learning, sentiment
e Feature engineering (Data Cleaning, PCA, VIF, Lasso, SMOTE) analysis - VADER)
¢ ML deployment (Hyperparameter tuning, Cross validation, ML e Data visualization (Tableau, Power BI, Qlik Sense, OAC,

Pipelines, Streaming Analytics) Microstrategy, R-shiny, Plotly)
© ML lifecycle (MLflow tracking, registration) e Data Engineering (Databricks, Structured Streaming, Hadoop
¢ ML framework (R, Scikit-learn, PySpark) ecosystem, Teradata, DB2/Oracle, EDW, Cloud migration)
e TS forecasting (Prophet, ARIMA) e AWS (EC2, S3, Redshift, SageMaker, Lambda, EventBridge)
¢ DL (TensorFlow) e Azure (Data Factory, SQL, ML Studio)

Work History
08/2019 to Current

04/2014 to 08/2019

11/2011 to 04/2014

e GCP (GCS, BigQuery, Cloud Composer, Cloud Function)
© DevOps platform (GitLab)

Consultant
Deloitte — Florham Park, NJ
e Client: CIO (Oct 2022 - Present)
© Modernizing Endpoint Security & Operations Infrastructure Project
© Client: Healthcare provider (Sep 2021 - Aug 2022)
© Provided development and leadership support to end-to-end execution and validation of data migration from legacy
on-prem (oracle, DB2) to cloud using GCP services (Cloud Function, Cloud Composer, GCS etc.), Databricks.
Databricks structured streaming is used to move CDC data (Kafka). It , also, involves configure, sizing and
optimization of Databricks Clusters.
¢ Develop machine learning capabilities on streaming data (streaming analytics) using PySpark/MLIib and ML
Pipelines. This is to provide Realtime prediction capability (i.e. member outreach, flight risk etc.) on large volume
of data.
© Client: Healthcare provider (Feb 2021 - Sep 2021)
Develop NLP based machine learning and deep learning models (TensorFlow) to analyze and predict claims
outcome (Azure/Databricks). Automated pipeline using HIVE metastore and Databricks Workflow.
Provide data and analytics support in Risk Adjustment and CMS Star Quality (experiences of Medicare
beneficiaries). Work involves understanding health insurance risk and quality concepts, Data transformation
(Azure/Databricks), automated pipeline (Databricks Jobs) and load (ArangoDB) for frontend D3_js reporting.
© Client: Global Pharmaceutical (Sep 2019 - May 2020)
Capacity modeling of clinical development network using process prediction (Bayesian regression) and discrete
event simulation (DES). Models include development network of oral solid dosage (OSD) drug product, small
molecule and biologics drug substance.
e Training data prepared and automated using AWS Redshift, SageMaker, Lambda and EventBridge. Frontend
developed and deployed using R-Shiny and Domino Data Lab.
¢ Client: Postal Services (Jul 2020 - Sep 2020)
¢ Develop end-to-end analytics and modeling strategies based on current processes and client's business need. This
involves connecting data sources to visualization platforms using database connectivity or REST API.
¢ Develop multi-class text classification model using Scikit-Learn on survey data (SurveyMonkey).
e Client: Natural Resources (Sep 2020 - Feb 2021)
¢ Implemented automated Data Pipeline using SAP BW, Power BI, powerapps and Data Gateway. It provides real-
time reporting of financial transactions, cost models and cost forecasting to the stakeholders.
© Utilize Azure ML Studio to develop model (multiple linear regression (MLR)) to predict cost per operating unit
and integrate with Power BI.

Continuous Improvement Lead
Tenneco Automotive — Elizabeth, New Jersey
¢ Develop end-to-end data solution using R-based data acquisition (on-premise SQL server, OSIsoft PI, LIMS),
transformation, predictive modeling (product classification, production outputs), visualization (R-shiny) and
deployment (LAN server).
¢ Implemented Power BI analytics and reporting capability.
¢ Develop engine failure model using Mine Haul Truck data for Hortonworks Hadoop environment (PySpark/
MLIhib).
e Time series forecasting of sales/demand and DES model development to determine EOQ.

Process Engineer
Glencore Plc — Sudbury, Ontario
¢ Statistical process control (SPC) and process capability analysis using Matlab.
e Copper-Nickel separation process optimization using predictive modeling (multiple linear regression) and design of
experiments (DOE).
¢ Implement maintenance contract management best practices by improved scheduling using MS Project, tracking
progress and conducting lessons learned.
¢ Develop maintenance KPIs using SAP and VBA to track PMs and cost overruns. Facilitate plant wide idea
generation.

Pusuic APPLICATIONS

© Web app to develop machine learning models (http://plotme.org/mlearn’)
¢ Processing Social Media (Twitter, Reddit etc.) feeds using Databricks, SQL and Data Visualization pipeline (https://
snowflectanalytics .shinyapps.io/socialNet’)